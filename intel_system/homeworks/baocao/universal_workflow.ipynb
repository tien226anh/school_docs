{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **The universal workflow of machine learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://images.datacamp.com/image/upload/v1662726672/image2_2daaea8e04.png\" style=\"width: 90vw\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có thể nói, đây là một quy trình tổng quát để giải quyết bất kỳ vấn đề nào trong machine learning. Tất nhiên, mỗi vấn đề sẽ có những đặc thù riêng, nhưng nói chung, chúng ta có thể áp dụng quy trình này để giải quyết bất kỳ vấn đề nào trong machine learning.\n",
    "\n",
    "Quy trình này được chia ra làm 3 phần chính:\n",
    "  1. **Define the task (Xác định nhiệm vụ chính)**: Hiểu được bài toán cần giải quyết là gì, đặc điểm của bài toán, các ràng buộc, các giả định, các giải pháp có sẵn, ... Thu thập dữ liệu, xử lý dữ liệu, hiểu được dữ liệu bao gồm những gì, ...\n",
    "  2. **Develop a model (Xây dựng mô hình)**: Chuẩn bị tập dữ liệu để có thể đưa vào mô hình, chọn mô hình phù hợp, huấn luyện model đầu tiên và đánh giá model đầu tiên. Từ những đánh giá đó, có thể tinh chỉnh model, tinh chỉnh dữ liệu, ... để có thể tạo ra model tốt hơn.\n",
    "  3. **Deploy the model (Triển khai mô hình)**: Đưa mô hình vào sử dụng, đánh giá mô hình trong thực tế, tinh chỉnh mô hình trong thực tế, ... Triển khai qua REST Api, triển khai lên giao diện người dùng từ REST Api có sẵn (web, mobile, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Define the task**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.1. Frame the problem (Đặt vấn đề)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đặt vấn đề là bước đầu tiên trong quy trình giải quyết bất kỳ vấn đề nào. Đặt vấn đề là bước quan trọng nhất trong quy trình giải quyết vấn đề. Nếu đặt vấn đề không đúng, thì cả quy trình giải quyết vấn đề sẽ không đúng. Dưới đây là những câu hỏi nên tự đặt cho bản thân:\n",
    "  * Dữ liệu đầu vào sẽ là gì? Bài toán của chúng ta muốn dự đoán gì? (Predict what?) Chúng ta chỉ có thể dự đoán (predict) một vật, điều gì đó chỉ khi chúng ta có tập dữ liệu phù hợp.\n",
    "\n",
    "  * Bài toán của chúng ta thuộc loại gì? Có thể là: phân loại nhị phân (binary classification), phân loại đa lớp (multiclass classification), phân loại đa nhãn (multilabel classification), hồi quy (regression), phân cụm (clustering), phát hiện bất thường (anomaly detection), ...? Ví dụ:\n",
    "    - Hệ thống tìm kiếm bằng hình ảnh (image search system): phân loại đa lớp (multiclass classification).\n",
    "    - Hệ thống phát hiện spam (spam detection system): phân loại nhị phân (binary classification).\n",
    "    - Hệ thống nhận diện chữ (optical character recognition system): phân loại đa nhãn (multilabel classification).\n",
    "  * Phương án giải quyết sẽ như thế nào? Chúng ta sẽ sử dụng phương pháp nào để giải quyết bài toán? Ví dụ:\n",
    "    - Hệ thống tìm kiếm bằng hình ảnh (image search system): sử dụng mạng nơ-ron tích chập (convolutional neural network).\n",
    "    - Hệ thống phát hiện spam (spam detection system): sử dụng mô hình học máy (machine learning model).\n",
    "    - Hệ thống nhận diện chữ (optical character recognition system): sử dụng mạng nơ-ron tích chập (convolutional neural network).\n",
    "  * Có những hạn chế cụ thể nào cần phải giải quyết? Ví dụ:\n",
    "    - Hệ thống tìm kiếm bằng hình ảnh (image search system): hệ thống chỉ có thể tìm kiếm được những hình ảnh có trong tập dữ liệu huấn luyện.\n",
    "    - Hệ thống phát hiện spam (spam detection system): hệ thống chỉ có thể phát hiện được những email có trong tập dữ liệu huấn luyện.\n",
    "    - Hệ thống nhận diện chữ (optical character recognition system): hệ thống chỉ có thể nhận diện được những chữ cái có trong tập dữ liệu huấn luyện."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2. Collect a dataset (Thu thập dữ liệu)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; flex-direction: column; align-items: center\">\n",
    "  <div style=\"width: 40vw\">\n",
    "    <img src='https://cdn.pixabay.com/photo/2022/01/30/13/33/github-6980894_1280.png'>\n",
    "    <img src='https://upload.wikimedia.org/wikipedia/commons/7/7c/Kaggle_logo.png'>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.3. Understand the data (Hiểu dữ liệu)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://editor.analyticsvidhya.com/uploads/22957fIRST.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Develop a model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. **Prepare the data (Xử lý dữ liệu)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các mô hình học máy về cơ bản không trực tiếp chạy qua dữ liệu thô (raw data). Quá trình tiền xử lý dữ liệu (data preprocessing) nắm vai trò biến dữ liệu thô thành kiểu dữ liệu phù hợp hơn với các công việc liên quan đến hệ thống neuron. Việc này bao gồm vector hóa (vectorization), chuẩn hóa (normalization), mã hóa (encoding), ... Các công việc tiền xử lý dữ liệu thường được thực hiện trước khi đưa dữ liệu vào mô hình học máy.\n",
    "\n",
    "  * **Vectorization:** Tất cả dữ liệu đầu vào và mục tiêu đầu ra trong hệ thống neuron đều phải được chuyển thành các tensor ở dạng số thực. Với bất kì dạng dữ liệu nào: âm thanh (sound), hình ảnh (images), chữ viết (text), ... đều phải được chuyển thành các tensor ở dạng số thực. Ví dụ:\n",
    "    - Hình ảnh: 3D tensor (samples, height, width, channels).\n",
    "    - Video: 5D tensor (samples, frames, height, width, channels).\n",
    "    - Văn bản: 2D tensor (samples, features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) =\\\n",
    "  imdb.load_data(num_words=10000)\n",
    "max([max(sequence) for sequence in train_data])\n",
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index=dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review=\" \".join([reverse_word_index.get(i-3, \"?\") for i in train_data[0]])\n",
    "import numpy as np\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequences in enumerate(sequences):\n",
    "        results[i, sequences] = 1.\n",
    "    return results\n",
    "X_train = vectorize_sequences(train_data)\n",
    "X_test = vectorize_sequences(test_data)\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "\n",
    "display(X_train[0], y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * **Value Normalization:** Các giá trị của dữ liệu đầu vào thường không cùng đơn vị, ví dụ: giá trị của một pixel trong ảnh có thể nằm trong khoảng từ 0 đến 255, trong khi đó giá trị của một từ trong văn bản có thể nằm trong khoảng từ 0 đến 10000. Việc này sẽ làm cho mô hình học máy khó hội tụ. Do đó, cần chuẩn hóa các giá trị của dữ liệu đầu vào về cùng một đơn vị. Ví dụ:\n",
    "    - Hình ảnh: chuẩn hóa giá trị của các pixel về khoảng từ 0 đến 1.\n",
    "    - Văn bản: chuẩn hóa giá trị của các từ về khoảng từ 0 đến 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph execution error:\n",
      "\n",
      "Detected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\runpy.py\", line 87, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\traitlets\\config\\application.py\", line 1046, in launch_instance\n",
      "      app.start()\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n",
      "      self.io_loop.start()\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "      self._run_once()\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "      handle._run()\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n",
      "      await result\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "      result = runner(coro)\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"C:\\Users\\tien2\\AppData\\Local\\Temp\\ipykernel_21844\\326910964.py\", line 19, in <module>\n",
      "      model.fit(train_images, train_labels, epochs=1, batch_size=128)\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1742, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n",
      "      loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n",
      "      return self.compiled_loss(\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n",
      "      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n",
      "      losses = call_fn(y_true, y_pred)\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\keras\\src\\losses.py\", line 268, in call\n",
      "      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\keras\\src\\losses.py\", line 2354, in sparse_categorical_crossentropy\n",
      "      return backend.sparse_categorical_crossentropy(\n",
      "    File \"c:\\Users\\tien2\\miniconda3\\envs\\intel\\lib\\site-packages\\keras\\src\\backend.py\", line 5762, in sparse_categorical_crossentropy\n",
      "      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "Node: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\n",
      "logits and labels must have the same first dimension, got logits shape [3584,10] and labels shape [128]\n",
      "\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_3083]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "display(train_images.shape, test_images.shape)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "try:\n",
    "  model.fit(train_images, train_labels, epochs=1, batch_size=128)\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 9s 17ms/step - loss: 2.3015 - accuracy: 0.1115\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 2.3014 - accuracy: 0.1124\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 2.3014 - accuracy: 0.1124\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 2.3014 - accuracy: 0.1124\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 2.3013 - accuracy: 0.1124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28c12356340>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255 \n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "display(train_images.shape, test_images.shape)\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 162ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.09866352, 0.11279394, 0.09947205, 0.10210522, 0.09705193,\n",
       "       0.09015024, 0.09924809, 0.10398537, 0.09743252, 0.0990971 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_digits = test_images[0:10]\n",
    "predictions = model.predict(test_digits)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. **Choose an evaluation protocol (Chọn giao thức xử lý)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Có 3 phương pháp phổ biến nhất:\n",
    "  - Simple holdout validation: chia tập dữ liệu thành 2 phần: tập huấn luyện (training set) và tập kiểm tra (test set).\n",
    "\n",
    "  <img src=\"https://community.alteryx.com/t5/image/serverpage/image-id/71542i222AF143484A2306/image-size/large?v=v2&px=999\">\n",
    "  <img src=\"https://community.alteryx.com/t5/image/serverpage/image-id/71548iB33D10C7233B394A/image-size/large?v=v2&px=999\"/>\n",
    "  \n",
    "  - K-fold validation: chia tập dữ liệu thành k phần, sẽ sử dụng k - 1 phần dữ liệu phục vụ việc huấn luyện mô hình, phần còn lại của mỗi k phần kia sẽ được sử dụng làm phần evaluate.\n",
    "  \n",
    "  <img src=\"https://community.alteryx.com/t5/image/serverpage/image-id/71553i43D85DE352069CB9/image-size/large?v=v2&px=999\">\n",
    "  \n",
    "  - Iterated K-fold validation with shuffling: chia tập dữ liệu thành k phần, mỗi phần sẽ được dùng lần lượt làm tập kiểm tra, các phần còn lại sẽ được dùng làm tập huấn luyện. Tuy nhiên, trước khi chia, tập dữ liệu sẽ được xáo trộn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. **Beat a baseline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Công việc chính ở bước này là xây dựng một mô hình đơn giản nhất có thể, một mô hình đơn giản nhất có thể là một mô hình hoàn toàn ngẫu nhiên. Mô hình này sẽ được dùng làm mô hình baseline để đánh giá các mô hình tiếp theo. Nếu mô hình tiếp theo không tốt hơn mô hình baseline, thì có thể xem như mô hình tiếp theo không có tác dụng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. **Develop a model that overfits**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Công việc chính ở mô hình này là xây dựng một mô hình có độ phức tạp cao, một mô hình có độ phức tạp cao có thể là một mạng nơ-ron có nhiều tầng ẩn, một mạng nơ-ron có nhiều tầng ẩn có thể là một mạng nơ-ron tích chập (convolutional neural network), một mạng nơ-ron tích chập có thể là một mạng nơ-ron tích chập sâu (deep convolutional neural network), ... Mô hình này sẽ được dùng để đánh giá mô hình tiếp theo. Nếu mô hình tiếp theo không tốt hơn mô hình có độ phức tạp cao, thì có thể xem như mô hình tiếp theo không có tác dụng. Có thể là:\n",
    "\n",
    "  - Thêm nhiều layer vào mạng nơ-ron.\n",
    "  - Làm cho mỗi layer có nhiều unit hơn (mở rộng layer).\n",
    "  - Tăng số epoch để huấn luyện lên nhiều hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Deploy the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhiệm vụ chính ở bước này là đánh giá mô hình trong thực tế, tinh chỉnh mô hình trong thực tế, ... Triển khai qua REST Api, triển khai lên giao diện người dùng từ REST Api có sẵn (web, mobile, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ví dụ:** Triển khai một mô hình học máy nhận dạng chữ viết tay (handwritten character recognition) lên giao diện người dùng (user interface) sử dụng FastAPI để phát triển REST Api và ReactJS để phát triển giao diện người dùng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/swagger.png\">\n",
    "<img src=\"./img/interface.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
